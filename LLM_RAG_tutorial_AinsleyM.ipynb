{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "osaDQ2rc12Ed"
      },
      "outputs": [],
      "source": [
        "# data retrieval for an LLm with RAG\n",
        "# peft would be used for fine-tuning the model\n",
        "# https://huggingface.co/docs/peft/index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QuTAcKC2Kqj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
            "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.11.1 which is incompatible.\n",
            "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
            "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.2 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "# intall dependencies:langchain and openAI\n",
        "#! pip install -qU langchain openai datasets transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbMljIQdEwio"
      },
      "source": [
        "Build knowledge base from pdfs\n",
        "- chunks will be embedded and stored in vector db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I1YZ5nlr2LYh"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "Module langchain_community.document_loaders not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Ainsley M\\anaconda3\\Lib\\site-packages\\langchain\\_api\\module_import.py:69\u001b[0m, in \u001b[0;36mcreate_importer.<locals>.import_by_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(new_module)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\Ainsley M\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n",
            "File \u001b[1;32mc:\\Users\\Ainsley M\\anaconda3\\Lib\\site-packages\\langchain\\document_loaders\\__init__.py:379\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    378\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Look up attributes dynamically.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _import_attribute(name)\n",
            "File \u001b[1;32mc:\\Users\\Ainsley M\\anaconda3\\Lib\\site-packages\\langchain\\_api\\module_import.py:72\u001b[0m, in \u001b[0;36mcreate_importer.<locals>.import_by_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_module\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_community\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 72\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install langchain-community to access this module. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can install it using `pip install -U langchain-community`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: Module langchain_community.document_loaders not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OdLFF5a2Lfr"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter( # defines the size of the chunk and overlap so chunks have some info from previous and upcoming chunks -play around with it\n",
        "    chunk_size = 300, # characters\n",
        "    chunk_overlap  = 50,# overlap between chunks in characters\n",
        "    length_function = len, # function to determine the length of a chunk\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t306mduj2LjY"
      },
      "outputs": [],
      "source": [
        "# make chunks\n",
        "filepath=\".\\jroijoifrjs.pdf\" # whatever pdf you want\n",
        "loader = PyPDFLoader(filepath)\n",
        "chunks = loader.load_and_split(text_splitter=text_splitter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvBxmDyo2Lme"
      },
      "outputs": [],
      "source": [
        "# display chunks\n",
        "for chunk in chunks:\n",
        "    print(\"Page_content:\\n\", chunk.page_content)\n",
        "    print(\"Page_Metadata:\\n\", chunk.metadata)\n",
        "    print(\"-------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U-Ds4Ye2LpG"
      },
      "outputs": [],
      "source": [
        "# vector DB:\n",
        "from langchain.vectorstores import Chroma # open source vector db can be run on local machine or ec2 instance on aws\n",
        "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdSDhEc72Lre"
      },
      "outputs": [],
      "source": [
        "# use open source embedding model to embed the chunks\n",
        "# create the function:\n",
        "embedding_function=SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\") # open AI also has a version of this, but this one can be run on local machine, many available on hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtC5Lwul2LuB"
      },
      "outputs": [],
      "source": [
        "# explain embeddings:\n",
        "embedding= embedding_function.embed_docments(\"This is a test\")\n",
        "print(embedding[0])\n",
        "print(\"Dimension of Embedding:\",len(embedding[0])) # some give 400-500, openai embedding model gives 1400 dimensions, more dimensions are better for detection accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrB8IzMUG8Ff"
      },
      "outputs": [],
      "source": [
        "# Upload chunks to vector db:\n",
        "# load it onto chroma\n",
        "db=Chroma.from_documents(chunks,embedding_function) # ,persist_directory=\"./chroma_db\" # took 13 seconds for him"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty2b2pFCHco2"
      },
      "outputs": [],
      "source": [
        "print(\"Chunks in db:\",db._collection.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVVV0ztWHpw6"
      },
      "outputs": [],
      "source": [
        "# set up retrieval from vector db\n",
        "query=\"what is automimune disease\"\n",
        "retriever=db.as_retriever()\n",
        "retriever.get_relevant_documents(query) # some chunks that get retrieved, and we will push these into the llm and it will give an answer based on that info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "587se9z9H-_Y"
      },
      "source": [
        "Setting up Rag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ycW56P5zH-lm",
        "outputId": "49abfe3d-8614-4ef3-b7d2-d43c0c444c6d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_community'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d7d1339d0384>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRetrievalQAWithSourcesChain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchat_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# If not in interactive env, raise warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLDy5kmSILjo"
      },
      "outputs": [],
      "source": [
        "# connect to LLM (openai)\n",
        "from utils import getkey\n",
        "OPENAI_API_KEY=getkey(key='MYKEY') # get my open ai api key from platform.openai.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prG8qw5IIvJF"
      },
      "outputs": [],
      "source": [
        "# set up llm connection\n",
        "llm=ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    # model_name='gpt-4'\n",
        "    temperature=0.0,\n",
        "    max_tokens=100, # could increase\n",
        "    # streaming=True\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V5xVWd2JGt4"
      },
      "outputs": [],
      "source": [
        "# connect vector db to llm:\n",
        "qa_with_sources=RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    #return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGgrLf8XJT-O"
      },
      "outputs": [],
      "source": [
        "# rag qa\n",
        "query=\"what is automimune disease\"\n",
        "qa_with_sources(query) # this gives the question, answer and source where it is coming from\n",
        "\n",
        "# when asked something not in the document it will say I don't know how to do that\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
