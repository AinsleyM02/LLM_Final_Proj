# Retrieval Augmented Generation for Health Education

### Abstract

The integration of large language models (LLMs) in medical education remains controversial due to concerns regarding the accuracy and reliability of generated information. The risk of disseminating incorrect information presents a barrier to their widespread adoption among students. Advanced technologies, including AI-driven chatbots, have the potential to accelerate student mastery of medical content by providing accessible, interactive learning resources. Thus, there is a critical need for the development of trustworthy, AI-based educational tools in this space. This project aims to develop an educational Medical Q&A Assistant that provides evidence-based medical knowledge, ensuring reliable learning for healthcare professionals. Our methodology involves collecting and preprocessing data from reputable medical resources, including public health guidelines, peer-reviewed research, and textbooks and encyclopedias. These resources will be pulled directly from the curriculum of a medical school class as a proof of concept. To ensure transparency and mitigate misinformation, the Q&A chatbot will include a disclaimer stating that the information is current as of a specific date and is intended as an educational tool for healthcare professionals. Sources will be cited on all responses. Ideally this RAG LLM can be used as a template for creating program specific LLMs.
